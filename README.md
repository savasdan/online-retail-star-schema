ğŸ“Š Online Retail â€“ Star Schema (Sales)
This project demonstrates the end-to-end design and implementation of a data warehouse star schema using the Online Retail dataset.
The focus of the project is data cleaning, dimensional modeling, and analytical readiness, following data engineering best practices.

ğŸ“¦ Dataset
	â€¢	Source: UCI Machine Learning Repository
	â€¢	Name: Online Retail Dataset
	â€¢	Link: https://archive.ics.uci.edu/dataset/352/online+retail
	â€¢	Original format: Excel (.xlsx)
The dataset contains transactional data for a UK-based online retail company.

ğŸ§± Project Architecture
The project follows a layered data pipeline approach:
1ï¸âƒ£ Raw Layer
	â€¢	Original dataset converted from Excel to CSV
	â€¢	Imported into MySQL using a Python script
2ï¸âƒ£ Staging / Cleaning Layer
	â€¢	A staging table (clean_online_retail) was created using SQL
	â€¢	Data cleaning rules applied:
	â—¦	Removed cancelled invoices
	â—¦	Filtered invalid quantities and prices
	â—¦	Handled missing customer values
	â—¦	Standardized text fields
	â—¦	Calculated revenue per invoice line
3ï¸âƒ£ Analytics Layer (Star Schema)
A star schema was designed and implemented for analytical workloads.

â­ Star Schema Design
Fact Table
fact_sales
	â€¢	Grain: one row per invoice line item
	â€¢	Measures:
	â—¦	quantity
	â—¦	unit_price
	â—¦	revenue
	â€¢	Primary Key:
	â—¦	surrogate key (sales_id)
	â€¢	Foreign Keys:
	â—¦	date_key
	â—¦	customer_id
	â—¦	stock_code
Dimension Tables
	â€¢	dim_date
	â—¦	date_key, date_value, year, month, day
	â€¢	dim_customer
	â—¦	customer_id, country
	â€¢	dim_product
	â—¦	stock_code, description

ğŸ—ºï¸ Entity Relationship Diagram (EER)
The final schema was visualized using MySQL Workbench.

ğŸ“ˆ The Cleaning Journey â€“ By the Numbers


Stage
Rows
What It Means
Raw Data
541,909
Every single record from the original system
Clean Data
397,884
Actual, valid sales we can analyze
Rows Removed
144,025
Data that didnâ€™t tell a useful business story
Thatâ€™s 144,025 rows of noise filtered out â€“ cancelled orders, system errors, and incomplete transactions â€“ leaving us with clean, trustworthy data for decision-making.
